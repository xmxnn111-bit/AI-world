import uvicorn
import asyncio
import logging
from typing import AsyncGenerator
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware

# å¦‚æœå°šæœªå®‰è£… DrissionPageï¼Œè¯·å…ˆå®‰è£…: pip install drissionpage
# from DrissionPage import ChromiumPage, ChromiumOptions

# é…ç½®ç®€å•çš„æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AIModelHandler:
    """
    ä¸šåŠ¡é€»è¾‘å±‚ï¼šè´Ÿè´£ç®¡ç†æµè§ˆå™¨å®ä¾‹åŠå¤„ç† AI å¯¹è¯é€»è¾‘ã€‚
    ç›®å‰å¤„äº Mock æ¨¡å¼ï¼Œç”¨äºè°ƒè¯•å‰ç«¯ WebSocket è¿æ¥å’Œæµå¼æ¸²æŸ“ã€‚
    """

    _instance = None

    def __new__(cls):
        """å®ç°å•ä¾‹æ¨¡å¼ï¼Œç¡®ä¿å…¨å±€åªæœ‰ä¸€ä¸ªæµè§ˆå™¨æ§åˆ¶å®ä¾‹"""
        if cls._instance is None:
            cls._instance = super(AIModelHandler, cls).__new__(cls)
            cls._instance.browser = None
        return cls._instance

    def initialize_browser(self):
        """
        åˆå§‹åŒ– DrissionPage æµè§ˆå™¨å¯¹è±¡ã€‚
        åœ¨çœŸå®ç¯å¢ƒä¸­ï¼Œè¿™é‡Œä¼šå¯åŠ¨ Chromium æµè§ˆå™¨ã€‚
        """
        logger.info("æ­£åœ¨åˆå§‹åŒ–æµè§ˆå™¨æœåŠ¡ (Mock Mode)...")
        # TODO: ã€çœŸå®é€»è¾‘æ›¿æ¢åŒºåŸŸã€‘
        # co = ChromiumOptions().auto_port()
        # self.browser = ChromiumPage(addr_or_opts=co)
        # logger.info("DrissionPage æµè§ˆå™¨å·²å¯åŠ¨ã€‚")
        pass

    async def chat_stream(self, model: str, message: str) -> AsyncGenerator[str, None]:
        """
        æ ¸å¿ƒç”Ÿæˆå™¨å‡½æ•°ï¼šæ¨¡æ‹Ÿ AI æµå¼å›å¤ã€‚

        Args:
            model (str): å‰ç«¯ä¼ é€’çš„æ¨¡å‹æ ‡è¯† (e.g., "gpt", "deepseek")
            message (str): ç”¨æˆ·è¾“å…¥çš„ prompt

        Yields:
            str: æ¯æ¬¡ç”Ÿæˆçš„æ–‡æœ¬ç‰‡æ®µ
        """
        logger.info(f"æ”¶åˆ°ç”Ÿæˆè¯·æ±‚ -> æ¨¡å‹: [{model}] | æ¶ˆæ¯: [{message}]")

        # 1. æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿå’Œ AI "æ€è€ƒ" æ—¶é—´
        await asyncio.sleep(1)

        # 2. å®šä¹‰æ¨¡æ‹Ÿå›å¤æ–‡æœ¬ (åŒ…å« Markdown æ ¼å¼ä»¥ä¾¿æµ‹è¯•å‰ç«¯æ¸²æŸ“)
        mock_response = (
            f"**[Mockæ¨¡å¼: {model}]**\n\n"
            f"æ”¶åˆ°ä½ çš„æ¶ˆæ¯ï¼š*{message}*\n\n"
            f"è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿçš„æµå¼å›å¤ã€‚åç«¯å¹¶æ²¡æœ‰çœŸæ­£è°ƒç”¨æµè§ˆå™¨ï¼Œè€Œæ˜¯é€šè¿‡ `asyncio` æ¨¡æ‹Ÿäº†æ‰“å­—æœºæ•ˆæœã€‚\n"
            f"åœ¨çœŸå®å¼€å‘é˜¶æ®µï¼Œè¿™é‡Œå°†è¢«æ›¿æ¢ä¸º DrissionPage çš„ç›‘å¬é€»è¾‘ï¼š\n"
            f"```python\n"
            f"# TODO: ç›‘å¬æµè§ˆå™¨æ•°æ®åŒ…\n"
            f"for packet in tab.listen.steps():\n"
            f"    yield packet.text\n"
            f"```\n"
            f"ç¥ä½ å‰ç«¯ React å¯¹æ¥é¡ºåˆ©ï¼ğŸš€"
        )

        # 3. æ¨¡æ‹Ÿæ‰“å­—æœºæµå¼è¾“å‡º (æ¯éš” 0.05ç§’ æ¨é€ä¸€ä¸ªå­—ç¬¦)
        # TODO: ã€çœŸå®é€»è¾‘æ›¿æ¢åŒºåŸŸã€‘æ­¤å¤„æœªæ¥å°†æ›¿æ¢ä¸º DrissionPage æŠ“å–åˆ°çš„å®æ—¶æ–‡æœ¬æµ
        for char in mock_response:
            yield char
            # éšæœºä¸€ç‚¹å¾®å°çš„å»¶è¿Ÿæ³¢åŠ¨ï¼Œè®©æ•ˆæœæ›´é€¼çœŸ
            await asyncio.sleep(0.02)

# --- FastAPI App è®¾ç½® ---

app = FastAPI(title="AI Nexus Backend", version="1.0.0")

# é…ç½®è·¨åŸŸèµ„æºå…±äº« (CORS)
# å…è®¸ React å¼€å‘æœåŠ¡å™¨ (é€šå¸¸æ˜¯ localhost:5173) è®¿é—®ï¼Œæˆ–å…è®¸æ‰€æœ‰ "*"
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒå»ºè®®æŒ‡å®šå…·ä½“åŸŸå
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ–ä¸šåŠ¡å¤„ç†å™¨å•ä¾‹
ai_handler = AIModelHandler()

@app.on_event("startup")
async def startup_event():
    """æœåŠ¡å¯åŠ¨æ—¶åˆå§‹åŒ–èµ„æº"""
    ai_handler.initialize_browser()

@app.on_event("shutdown")
async def shutdown_event():
    """æœåŠ¡å…³é—­æ—¶æ¸…ç†èµ„æº"""
    if ai_handler.browser:
        # ai_handler.browser.quit() # å…³é—­æµè§ˆå™¨
        logger.info("æµè§ˆå™¨èµ„æºå·²é‡Šæ”¾ã€‚")

# --- WebSocket è·¯ç”± ---

@app.websocket("/ws/chat")
async def websocket_endpoint(websocket: WebSocket):
    """
    å¤„ç† /ws/chat çš„ WebSocket è¿æ¥
    """
    await websocket.accept()
    logger.info("å‰ç«¯ WebSocket å·²è¿æ¥")

    try:
        while True:
            # 1. æ¥æ”¶å‰ç«¯ JSON æ•°æ®
            # æ ¼å¼: {"model": "gpt", "message": "hello"}
            data = await websocket.receive_json()

            user_model = data.get("model", "unknown")
            user_message = data.get("message", "")

            if not user_message:
                continue

            # 2. è°ƒç”¨ä¸šåŠ¡é€»è¾‘å±‚ï¼Œè·å–æµå¼ç”Ÿæˆå™¨
            stream_generator = ai_handler.chat_stream(user_model, user_message)

            # 3. è¿­ä»£ç”Ÿæˆå™¨ï¼Œå®æ—¶æ¨é€æ•°æ®ç»™å‰ç«¯
            async for text_chunk in stream_generator:
                # ç›´æ¥å‘é€æ–‡æœ¬ç‰‡æ®µ
                await websocket.send_text(text_chunk)

            # 4. ç»“æŸæ ‡å¿—ï¼šå‘é€ç‰¹å®šå­—ç¬¦ä¸²å‘Šè¯‰å‰ç«¯æœ¬æ¬¡ç”Ÿæˆç»“æŸ
            # å‰ç«¯æ”¶åˆ°æ­¤æ ‡è®°åï¼Œåº”åœæ­¢åŠ è½½åŠ¨ç”»å¹¶å¯ç”¨è¾“å…¥æ¡†
            await websocket.send_text("[DONE]")

    except WebSocketDisconnect:
        logger.warning("å‰ç«¯æ–­å¼€è¿æ¥ (WebSocketDisconnect)")
    except Exception as e:
        logger.error(f"WebSocket å†…éƒ¨é”™è¯¯: {str(e)}")
        # å‘ç”Ÿé”™è¯¯æ—¶ä¹Ÿå¯ä»¥å°è¯•å‘é€ä¸€ä¸ªé”™è¯¯æç¤ºç»™å‰ç«¯ï¼Œé˜²æ­¢å‰ç«¯ä¸€ç›´ loading
        try:
            await websocket.send_text(f"Error: {str(e)}")
            await websocket.send_text("[DONE]")
        except:
            pass

if __name__ == "__main__":
    # å¯åŠ¨å¼€å‘æœåŠ¡å™¨
    # è®¿é—®åœ°å€: ws://127.0.0.1:8000/ws/chat
    print("æ­£åœ¨å¯åŠ¨ AI Nexus åç«¯æœåŠ¡...")
    uvicorn.run("main:app", host="127.0.0.1", port=8000, reload=True)